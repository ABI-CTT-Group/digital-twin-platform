{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Finding and downloading datasets from the DigitalTWINS platform using the digitaltwins-api\n",
    "\n",
    "## Introduction\n",
    "The 12 LABOURS DigitalTWINS Platformâ€™s harmonised database is organised into **Programs** and **Projects**. For example, Exemplar Project 1 (**EP1**) is a project within the 12 LABOURS (**12L**) Program. Users can only access and download datasets from these projects once they have been granted access. See Tutorial 1 for information on how to request access and connect to the platform. This tutorial shows how to find and download existing datasets from the DigitalTWINS Platform's portal or its Python API.\n",
    "\n",
    "## Definitions\n",
    "- API - Application Programming Interface used to access the features or data of an application or service.\n",
    "\n",
    "## Learning outcomes\n",
    "In this tutorial, you will learn how to:\n",
    "- find existing datasets stored in the platform's portal.\n",
    "- access the platform using the `digitaltwins` Python API and find existing datasets.\n",
    "- download datasets in SDS format using the `digitaltwins` Python API.\n",
    "\n",
    "## Finding datasets\n",
    "Each dataset stored in the platform has a unique identifier (ID) e.g. `12L-EP1-dataset-1-version-1`.\n",
    "\n",
    "### Finding datasets using the platform's portal\n",
    "Dataset IDs are included in each dataset listed on the data catalogue page of the 12 LABOURS DigitalTWINS platform's portal (see screenshots below). Please see Tutorial 1 for instructions for how to connect to an instance of the platform and open its portal in a local web browser.\n",
    "\n",
    "### Finding datasets in the platform using the `digitaltwins` Python API\n",
    "Using the `digitaltwins` Python API requires a `config.ini` file that specifies the location and API access keys for your instance of the DigitalTWINS Platform. Please see [Tutorial 1](https://github.com/ABI-CTT-Group/digitaltwins-api/blob/main/tutorials/tutorial_1_getting_started.md) for information on how to access the `config.ini` file for your instance of the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-20T04:00:22.452245800Z",
     "start_time": "2023-09-20T04:00:22.431249500Z"
    }
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "# Change the path below to point to the location of your config.ini file as described in Tutorial 1.\n",
    "config_file = pathlib.Path(r\"L:\\DigitalTWINS\\resources\\latest\\configs\\configs.ini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `digitaltwins` Python API's `Querier` class to list or search for existing datasets in the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-20T04:00:26.444210800Z",
     "start_time": "2023-09-20T04:00:26.358213100Z"
    }
   },
   "outputs": [],
   "source": [
    "import digitaltwins as dts\n",
    "\n",
    "querier = dts.Querier(config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please let one of the workshop organisers know if you encounter an error with querying the platform.**\n",
    "\n",
    "#### Listing program and projects in the platform\n",
    "\n",
    "A list of existing programs in the platform can be retrieved as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-20T04:00:30.851227200Z",
     "start_time": "2023-09-20T04:00:29.366856300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request...\n",
      "[2023-09-20 16:00:29,447][WARNING] failed to write token cache file: C:\\Users\\clin864/.cache/gen3/token_cache_9d1f0f305f992c9ce77507807d49a356\n",
      "[2023-09-20 16:00:29,448][WARNING] [WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\clin864/.cache/gen3/token_cache_9d1f0f305f992c9ce77507807d49a356.tmp_eraseme_93569_1695182429' -> 'C:\\\\Users\\\\clin864/.cache/gen3/token_cache_9d1f0f305f992c9ce77507807d49a356'\n",
      "[2023-09-20 16:00:29,449][WARNING] backoff: call gen3.auth._write_to_file(<gen3.auth.Gen3Auth object at 0x000002A4F489D1C0>, C:\\Users\\clin864/.cache/gen3/token_cache_9d1f0f305f992c9ce77507807d49a356, eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImtpZCI6ImZlbmNlX2tleV8yMDIzLTA5LTExVDAyOjQwOjU2WiJ9.eyJwdXIiOiJhY2Nlc3MiLCJhdWQiOlsiZGF0YSIsInVzZXIiLCJmZW5jZSIsIm9wZW5pZCJdLCJzdWIiOiIxIiwiaXNzIjoiaHR0cHM6Ly9sb2NhbGhvc3QvdXNlciIsImlhdCI6MTY5NTE4MjQyOSwiZXhwIjoxNjk1MTg2MDI5LCJqdGkiOiI4MWZjNzQxMS1jM2Q3LTQ3NDAtYTMyOS00MzAzZjU2MTllODIiLCJzY29wZSI6WyJkYXRhIiwidXNlciIsImZlbmNlIiwib3BlbmlkIl0sImNvbnRleHQiOnsidXNlciI6eyJuYW1lIjoidGVzdCIsImlzX2FkbWluIjpmYWxzZSwiZ29vZ2xlIjp7InByb3h5X2dyb3VwIjpudWxsfSwicHJvamVjdHMiOnt9fX0sImF6cCI6IiJ9.cOoTBrDbbDAn1o87KK9MWQ03NiV5ALVrAGY5WWUG2Kysa8-NChduq2fFNE7B6VAl7xSzApGfTLFTXubJb9l-3sRnorS9WhXBdiF1_P3nyeV0jcliCYG2Zs4jiyoZq-mW0yGp0PNEPLTV0qGFPZ5GVLbEuedCG15qbMGsNuLltvoYU86ChDg1F0ddnpRsAS2qmlH-eeXFA8sv4kLXX0BGWL1tqheOV79e6pVgCAeNgu583HLVVy-o9NnLOX0h94QUQdiG59C2ASzaIe0lVuQaXjSpIo__OFTBFQU5-i9CkYfuZ-tKFU-hSINw77TrN_kkF530zmb2QBR9ridaRZWzig) delay 0.2 seconds after 1 tries\n",
      "[2023-09-20 16:00:29,634][WARNING] failed to write token cache file: C:\\Users\\clin864/.cache/gen3/token_cache_9d1f0f305f992c9ce77507807d49a356\n",
      "[2023-09-20 16:00:29,635][WARNING] [WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\clin864/.cache/gen3/token_cache_9d1f0f305f992c9ce77507807d49a356.tmp_eraseme_41085_1695182429' -> 'C:\\\\Users\\\\clin864/.cache/gen3/token_cache_9d1f0f305f992c9ce77507807d49a356'\n",
      "[2023-09-20 16:00:29,636][WARNING] backoff: call gen3.auth._write_to_file(<gen3.auth.Gen3Auth object at 0x000002A4F489D1C0>, C:\\Users\\clin864/.cache/gen3/token_cache_9d1f0f305f992c9ce77507807d49a356, eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImtpZCI6ImZlbmNlX2tleV8yMDIzLTA5LTExVDAyOjQwOjU2WiJ9.eyJwdXIiOiJhY2Nlc3MiLCJhdWQiOlsiZGF0YSIsInVzZXIiLCJmZW5jZSIsIm9wZW5pZCJdLCJzdWIiOiIxIiwiaXNzIjoiaHR0cHM6Ly9sb2NhbGhvc3QvdXNlciIsImlhdCI6MTY5NTE4MjQyOSwiZXhwIjoxNjk1MTg2MDI5LCJqdGkiOiI4MWZjNzQxMS1jM2Q3LTQ3NDAtYTMyOS00MzAzZjU2MTllODIiLCJzY29wZSI6WyJkYXRhIiwidXNlciIsImZlbmNlIiwib3BlbmlkIl0sImNvbnRleHQiOnsidXNlciI6eyJuYW1lIjoidGVzdCIsImlzX2FkbWluIjpmYWxzZSwiZ29vZ2xlIjp7InByb3h5X2dyb3VwIjpudWxsfSwicHJvamVjdHMiOnt9fX0sImF6cCI6IiJ9.cOoTBrDbbDAn1o87KK9MWQ03NiV5ALVrAGY5WWUG2Kysa8-NChduq2fFNE7B6VAl7xSzApGfTLFTXubJb9l-3sRnorS9WhXBdiF1_P3nyeV0jcliCYG2Zs4jiyoZq-mW0yGp0PNEPLTV0qGFPZ5GVLbEuedCG15qbMGsNuLltvoYU86ChDg1F0ddnpRsAS2qmlH-eeXFA8sv4kLXX0BGWL1tqheOV79e6pVgCAeNgu583HLVVy-o9NnLOX0h94QUQdiG59C2ASzaIe0lVuQaXjSpIo__OFTBFQU5-i9CkYfuZ-tKFU-hSINw77TrN_kkF530zmb2QBR9ridaRZWzig) delay 0.5 seconds after 2 tries\n",
      "[2023-09-20 16:00:30,099][WARNING] failed to write token cache file: C:\\Users\\clin864/.cache/gen3/token_cache_9d1f0f305f992c9ce77507807d49a356\n",
      "[2023-09-20 16:00:30,100][WARNING] [WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\clin864/.cache/gen3/token_cache_9d1f0f305f992c9ce77507807d49a356.tmp_eraseme_95716_1695182430' -> 'C:\\\\Users\\\\clin864/.cache/gen3/token_cache_9d1f0f305f992c9ce77507807d49a356'\n",
      "[2023-09-20 16:00:30,101][  ERROR] backoff: gave up call gen3.auth._write_to_file(<gen3.auth.Gen3Auth object at 0x000002A4F489D1C0>, C:\\Users\\clin864/.cache/gen3/token_cache_9d1f0f305f992c9ce77507807d49a356, eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImtpZCI6ImZlbmNlX2tleV8yMDIzLTA5LTExVDAyOjQwOjU2WiJ9.eyJwdXIiOiJhY2Nlc3MiLCJhdWQiOlsiZGF0YSIsInVzZXIiLCJmZW5jZSIsIm9wZW5pZCJdLCJzdWIiOiIxIiwiaXNzIjoiaHR0cHM6Ly9sb2NhbGhvc3QvdXNlciIsImlhdCI6MTY5NTE4MjQyOSwiZXhwIjoxNjk1MTg2MDI5LCJqdGkiOiI4MWZjNzQxMS1jM2Q3LTQ3NDAtYTMyOS00MzAzZjU2MTllODIiLCJzY29wZSI6WyJkYXRhIiwidXNlciIsImZlbmNlIiwib3BlbmlkIl0sImNvbnRleHQiOnsidXNlciI6eyJuYW1lIjoidGVzdCIsImlzX2FkbWluIjpmYWxzZSwiZ29vZ2xlIjp7InByb3h5X2dyb3VwIjpudWxsfSwicHJvamVjdHMiOnt9fX0sImF6cCI6IiJ9.cOoTBrDbbDAn1o87KK9MWQ03NiV5ALVrAGY5WWUG2Kysa8-NChduq2fFNE7B6VAl7xSzApGfTLFTXubJb9l-3sRnorS9WhXBdiF1_P3nyeV0jcliCYG2Zs4jiyoZq-mW0yGp0PNEPLTV0qGFPZ5GVLbEuedCG15qbMGsNuLltvoYU86ChDg1F0ddnpRsAS2qmlH-eeXFA8sv4kLXX0BGWL1tqheOV79e6pVgCAeNgu583HLVVy-o9NnLOX0h94QUQdiG59C2ASzaIe0lVuQaXjSpIo__OFTBFQU5-i9CkYfuZ-tKFU-hSINw77TrN_kkF530zmb2QBR9ridaRZWzig) after 3 tries; exception: (<class 'FileExistsError'>, FileExistsError(17, 'Cannot create a file when that file already exists'), <traceback object at 0x000002A4F4889AC0>)\n",
      "[2023-09-20 16:00:30,102][WARNING] Unable to write access token to cache file. Exceeded number of retries. Details: [WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\clin864/.cache/gen3/token_cache_9d1f0f305f992c9ce77507807d49a356.tmp_eraseme_95716_1695182430' -> 'C:\\\\Users\\\\clin864/.cache/gen3/token_cache_9d1f0f305f992c9ce77507807d49a356'\n"
     ]
    }
   ],
   "source": [
    "programs = querier.get_all_programs()\n",
    "print(programs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of existing projects within a program can be retrieved as follows. The optional `program` argument can be used to list projects in a specific program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-20T04:03:51.488300600Z",
     "start_time": "2023-09-20T04:03:51.326302200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request...\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'name': 'EP2A'}, {'name': '12L'}, {'name': 'EP2'}, {'name': 'EP1'}]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects = querier.get_projects_by_program(program=\"12L\")\n",
    "print(projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-20T04:04:39.252777500Z",
     "start_time": "2023-09-20T04:04:38.855229600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request...\n",
      "12L-12L-dataset-1-version-1\n",
      "program1-P1-dataset-1-version-1\n"
     ]
    }
   ],
   "source": [
    "datasets = querier.get_datasets()\n",
    "for dataset in datasets:\n",
    "    print(dataset.get_id())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the platform's API to search for datasets\n",
    "The `search_datasets` method of the `Querier` class allows for searching of datasets, and returns a python list of `Dataset` objects that match the search criteria . \n",
    "\n",
    "Currently, only searching text that matches exactly with the title of existing datasets in the platform is currently supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-20T04:04:47.447366200Z",
     "start_time": "2023-09-20T04:04:47.301365300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request...\n",
      "12L-12L-dataset-1-version-1\n"
     ]
    }
   ],
   "source": [
    "dataset_id = '12L-EP1-dataset-1-version-1'\n",
    "dataset = querier.get_dataset(dataset_id)\n",
    "print(dataset.get_id())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading datasets\n",
    "Datasets are stored in SDS format within the platforms harmonised database. We can use the DigitalTWINS Python API's `Downloader` class to select and download a dataset in SDS format. Once downloaded, the `sparc-me` Python module can be used explore the metadata in a dataset (see Tutorial 3).\n",
    "\n",
    "By default, datasets are downloaded to the current working directory, however, the `save_dir` optional argument can be specified to select a different download destination path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-20T04:06:08.032457600Z",
     "start_time": "2023-09-20T04:06:02.158108800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset 12L-12L-dataset-1-version-1\n",
      "Dataset successfully downloaded\n"
     ]
    }
   ],
   "source": [
    "downloader = dts.Downloader(config_file)\n",
    "downloader.download(dataset_id, save_dir='./tmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please let one of the workshop organisers know if you encounter an error with downloading datasets.**\n",
    "\n",
    "## Feedback\n",
    "Once you have completed this tutorial, please complete [this survey](https://docs.google.com/forms/d/e/1FAIpQLSe-EsVz6ahz2FXFy906AZh68i50jRYnt3hQe-loc-1DaFWoFQ/viewform?usp=sf_link), which will allow us to improve this and future tutorials.\n",
    "\n",
    "## Next steps\n",
    "The [next tutorial](https://github.com/ABI-CTT-Group/digitaltwins-api/blob/main/tutorials/tutorial_3_loading_and_exploring_sds_datasets.ipynb) will show how to load and explore SDS datasets using the sparc-me Python tool."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
