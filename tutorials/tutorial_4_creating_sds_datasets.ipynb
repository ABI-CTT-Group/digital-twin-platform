{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 4: Creating SDS datasets using sparc-me\n",
    "\n",
    "## Introduction\n",
    "This tutorial shows how to create new datasets in the SPARC Data Structure (SDS) format using the [sparc-me python tool](https://github.com/SPARC-FAIR-Codeathon/sparc-me).\n",
    "\n",
    "## Definitions\n",
    "- samples SDS metadata file - See the following [presentation](https://docs.google.com/file/d/1zZ3-C17lPIgtRp6bnkSwvKacaTA66GVR/edit?usp=docslist_api&filetype=mspresentation) for more information.\n",
    "- subjects SDS metadata file - See the following [presentation](https://docs.google.com/file/d/1zZ3-C17lPIgtRp6bnkSwvKacaTA66GVR/edit?usp=docslist_api&filetype=mspresentation) for more information.\n",
    "\n",
    "## Learning outcomes\n",
    "In this tutorial, you will learn how to:\n",
    "- create an empty dataset from a SDS template.\n",
    "- add or modify metadata element values.\n",
    "- add or remove data from a dataset.\n",
    "\n",
    "## Creating a dataset using a template\n",
    "\n",
    "We will use `sparc-me`'s `Dataset` Python Class to create an empty dataset using a template and return it as a Python object.\n",
    "\n",
    "You can specify the path for where the generated dataset will be stored as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparc_me as sm\n",
    "import warnings\n",
    "\n",
    "dataset = sm.Dataset()\n",
    "dataset.set_path('./example_sds_dataset')\n",
    "dataset.create_empty_dataset(version='2.0.0')\n",
    "\n",
    "# Suppress deprecation warning from python modules.\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any changes to a dataset will automatically update the dataset.\n",
    "\n",
    "## Adding or modifying metadata\n",
    "Tutorial 3 described how we can use sparc-me to get the value of metadata elements used in the different metadata files of an SDS dataset.\n",
    "\n",
    "We will now show how to add metadata elements for the dataset description metadata file.\n",
    "\n",
    "As mentioned in Tutorial 3, information about a metadata element can be accessed through the SDS documentation or using sparc-me's schema methods.\n",
    "\n",
    "### Dataset Description\n",
    "We can create a `Metadata` Python object for the metadata file of interest using the `Dataset` object's `get_metadata` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = dataset.get_metadata(metadata_file='dataset_description')  # dd is short for dataset_description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then easily add values for metadata elements using the metadata object's `add_values` Python method:\n",
    "\n",
    "```\n",
    "add_values(\n",
    "  element: str = '',\n",
    "  values: Any, \n",
    "  append: bool = True)\n",
    "```\n",
    "\n",
    "Note that by default, `add_values` will append to existing metadata element values, unless the optional `append` argument is set to `False`, in which case, any existing values are replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.add_values(\n",
    "    element='Type', \n",
    "    values='Experimental')\n",
    "dd.add_values(\n",
    "    element='Title', \n",
    "    values='Duke University DCE-MRI of breast cancer patients')\n",
    "dd.add_values(\n",
    "    element='Subtitle',\n",
    "    values='Retrospective collection of MRI from 922 biopsy-confirmed invasive breast cancer patients.')\n",
    "dd.add_values(\n",
    "    element='Keywords', \n",
    "    values=['Breast cancer','MRI'])\n",
    "dd.add_values(\n",
    "    element='Study purpose',\n",
    "    values='Breast MRI is a medical image modality used to assess the extent of disease in breast cancer patients. Recent studies show that MRI has a potential in prognosis of patientsâ€™ short and long-term outcomes as well as predicting pathological and genomic features of the tumors. However, large, well annotated datasets are needed to make further progress in the field. We share such a dataset here.')\n",
    "dd.add_values(\n",
    "    element='Study data Collection',\n",
    "    values=\"\"\"This dataset is a single-institutional, retrospective collection of 922 biopsy-confirmed invasive breast cancer patients, over a decade, specifically pre-operative dynamic contrast enhanced (DCE)-MRI that were downloaded from PACS systems and de-identified for The Cancer Imaging Archive (TCIA) release. These include axial breast MRI images acquired by 1.5T or 3T scanners in the prone positions. The following MRI sequences are shared in DICOM format: a non-fat saturated T1-weighted sequence, a fat-saturated gradient echo T1-weighted pre-contrast sequence, and mostly three to four post-contrast sequences.\"\"\")\n",
    "dd.add_values(\n",
    "    element='Study primary conclusion', \n",
    "    values='Data collected for subsequent analysis.')\n",
    "dd.add_values(\n",
    "    element='Study organ system', \n",
    "    values='breast')\n",
    "dd.add_values(\n",
    "    element='Study approach', \n",
    "    values='Imaging')\n",
    "dd.add_values(\n",
    "    element='Study technique', \n",
    "    values='MRI')\n",
    "dd.add_values(\n",
    "    element='Contributorname', \n",
    "    values=['Saha, Ashirbani',\n",
    "            'Harowicz, Michael R',\n",
    "            'Grimm, Lars J',\n",
    "            'Kim, Connie E',\n",
    "            'Ghate, Sujata V',\n",
    "            'Walsh, Ruth',\n",
    "            'Mazurowski, Maciej A'])\n",
    "dd.add_values(\n",
    "    element='Contributor orcid',\n",
    "    values=['https://orcid.org/0000-0002-7650-1720',\n",
    "            'https://orcid.org/0000-0002-8002-5210',\n",
    "            'https://orcid.org/0000-0002-3865-3352',\n",
    "            'https://orcid.org/0000-0003-0730-0551',\n",
    "            'https://orcid.org/0000-0003-1889-982X',\n",
    "            'https://orcid.org/0000-0002-2164-2761',\n",
    "            'https://orcid.org/0000-0003-4202-8602'],)\n",
    "\n",
    "dd.add_values(\n",
    "    element='Identifier',\n",
    "    values='Not Defined')\n",
    "\n",
    "dd.add_values(\n",
    "    element='Identifier description',\n",
    "    values='Not Defined')\n",
    "\n",
    "dd.add_values(\n",
    "    element='Relation type',\n",
    "    values='Not Defined')\n",
    "\n",
    "dd.add_values(\n",
    "    element='Identifier type',\n",
    "    values='Not Defined')\n",
    "\n",
    "dd.add_values(\n",
    "    element='Contributor affiliation', \n",
    "    values=['Duke University'] * 7)\n",
    "dd.add_values(\n",
    "    element='Contributor role',\n",
    "    values=['Researcher',\n",
    "            'Researcher',\n",
    "            'Researcher',\n",
    "            'Researcher',\n",
    "            'Researcher',\n",
    "            'Researcher',\n",
    "            'Researcher'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described in Tutorial 3, we can get the metadata element values we have just added as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.get_values(element='Contributor role')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A specific metadata element value can be removed as follows. Note that if more than one match is found, all matches are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.remove_values(\n",
    "    element='Contributor role',\n",
    "    values = 'Researcher'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All values for a metadata element can also be cleared, e.g.  `dd.clear_values(element='Contributor role')`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding or removing data\n",
    "Adding data to a SDS dataset using `sparc-me` involves specifying the location of all the files or folders that should be placed in the sample folder for a subject. The organisation of the data within the sample folder is left to the user creating the dataset.\n",
    "\n",
    "Future releases of sparc-me and the DigitalTWINS platform API will include the ability to:\n",
    "- add subjects and samples to an existing dataset;\n",
    "- remove subjects and sample; and\n",
    "- version control of datasets.\n",
    "Until then, **if at any stage, any new subjects or samples need to be added or removed, please discard the dataset being created and create a new one**.\n",
    "\n",
    "The following code snippet shows one example of how subjects and samples can be added to a dataset. Two breast MRI sequences for two subjects will be added to the dataset. In this case, each sample represents a different MRI sequence.\n",
    "\n",
    "Please see Tutorial 1 for instructions for how to get access to the raw data that can be used with this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = []\n",
    "samples = []\n",
    "\n",
    "sample1 = sm.Sample()\n",
    "# Change the path below to point to the location of example_raw_dataset folder as described in Tutorial 1.\n",
    "sample1.add_path(r\"X:\\DigitalTWINS\\resources\\latest\\example_datasets\\example_raw_dataset\\Breast_MRI_001\\sequence1\") # adding a folder\n",
    "samples.append(sample1)\n",
    "\n",
    "sample2 = sm.Sample()\n",
    "sample2.add_path(r\"X:\\DigitalTWINS\\resources\\latest\\example_datasets\\example_raw_dataset\\Breast_MRI_001\\sequence2\\1-001.dcm\") # adding a file\n",
    "sample2.add_path([\n",
    "    r\"X:\\DigitalTWINS\\resources\\latest\\example_datasets\\example_raw_dataset\\Breast_MRI_001\\sequence2\\1-002.dcm\",\n",
    "    r\"X:\\DigitalTWINS\\resources\\latest\\example_datasets\\example_raw_dataset\\Breast_MRI_001\\sequence2\\1-003.dcm\",\n",
    "    r\"X:\\DigitalTWINS\\resources\\latest\\example_datasets\\example_raw_dataset\\Breast_MRI_001\\sequence2\\1-004.dcm\"]) # adding a list of files\n",
    "samples.append(sample2)\n",
    "\n",
    "subject1 = sm.Subject()\n",
    "subject1.add_samples(samples)\n",
    "subjects.append(subject1)\n",
    "\n",
    "samples=[]\n",
    "sample1 = sm.Sample()\n",
    "sample1.add_path(r\"X:\\DigitalTWINS\\resources\\latest\\example_datasets\\example_raw_dataset\\Breast_MRI_002\\sequence1\")\n",
    "samples.append(sample1)\n",
    "\n",
    "sample2 = sm.Sample()\n",
    "sample2.add_path(r\"X:\\DigitalTWINS\\resources\\latest\\example_datasets\\example_raw_dataset\\Breast_MRI_002\\sequence2\")\n",
    "samples.append(sample2)\n",
    "\n",
    "subject2 = sm.Subject()\n",
    "subject2.add_samples(samples)\n",
    "subjects.append(subject2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way the above code can be simplified is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "```\n",
    "subjects = []\n",
    "for subject_user_id in [1, 2]:\n",
    "    samples = []\n",
    "    for sample_user_id in [1, 2]:\n",
    "        sample = sm.Sample()\n",
    "        sample.add_path(\n",
    "            \"../resources/example_raw_dataset/Breast_MRI_00{0}/sequence{1}/\".format(\n",
    "                subject_user_id, sample_user_id))\n",
    "        samples.append(sample)\n",
    "    subject = sm.Subject()\n",
    "    subject.add_samples(samples)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the path for the samples of each subject has been specified, they can be added to the dataset as shown below. This will copy the data from its user specified location, to the subject and sample folders within the primary data folder of the SDS dataset being created. Note that the samples and subjects will be renumbered sequentially, and may not correspond to the user_ids. This will also automatically update the manifest SDS metadata file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.add_subjects(subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to add the required and additional metadata elements in the subjects and samples SDS metadata files. All metadata elements in the subjects and samples metadata files can be listed as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "schema = sm.Schema()\n",
    "subjects_schema = schema.get_schema(\n",
    "    metadata_file='subjects', print_schema=True)\n",
    "pprint(subjects_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_subjects_schema = schema.get_schema(\n",
    "    metadata_file='subjects', print_schema=False, required_only=True, name_only=False)\n",
    "pprint(required_subjects_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The code below shows how to list only the required metadata elements for the subjects and samples SDS metadata files."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "samples_schema = schema.get_schema(\n",
    "    metadata_file='samples', print_schema=True)\n",
    "pprint(samples_schema)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "required_samples_schema = schema.get_schema(\n",
    "    metadata_file='samples', print_schema=False, required_only=True, name_only=False)\n",
    "pprint(required_samples_schema)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we are aware of which metadata elements are used to describe the data that was added to the dataset (and which metadata elements are required), the code below shows an example of how the values for these metadata fields can be added to the dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_sds_id = \"sub-1\"\n",
    "subject = dataset.get_subject(subject_sds_id)\n",
    "subject.set_value(\n",
    "    element='subject experimental group',\n",
    "    value='Control')\n",
    "\n",
    "sample_sds_id = \"sam-1\"\n",
    "sample = subject.get_sample(sample_sds_id)\n",
    "sample.set_value(\n",
    "    element='sample experimental group',\n",
    "    value='Experimental')\n",
    "\n",
    "sample_sds_id = \"sam-2\"\n",
    "sample = subject.get_sample(sample_sds_id)\n",
    "sample.set_value(\n",
    "    element='sample experimental group',\n",
    "    value='Experimental')\n",
    "\n",
    "subject_sds_id = \"sub-2\"\n",
    "subject = dataset.get_subject(subject_sds_id)\n",
    "subject.set_value(\n",
    "    element='subject experimental group',\n",
    "    value='Control')\n",
    "\n",
    "sample_sds_id = \"sam-1\"\n",
    "sample = subject.get_sample(sample_sds_id)\n",
    "sample.set_value(\n",
    "    element='sample experimental group',\n",
    "    value='Experimental')\n",
    "\n",
    "sample_sds_id = \"sam-2\"\n",
    "sample = subject.get_sample(sample_sds_id)\n",
    "sample.set_value(\n",
    "    element='sample experimental group',\n",
    "    value='Experimental')\n",
    "\n",
    "ages = ['30y', '20y']\n",
    "sex = ['Female'] * 2 #  Create a list with duplicated items of the size specified.\n",
    "species = ['Human']* 2\n",
    "strain = ['Not Defined'] * 2\n",
    "RRID_for_strain = ['Not Defined'] * 2\n",
    "age_category = ['Prime Adult Stage'] * 2\n",
    "also_in_dataset = ['Not Defined'] * 2\n",
    "member_of = ['Not Defined'] * 2\n",
    "\n",
    "for idx, subject_sds_id in enumerate([\"sub-1\", \"sub-2\"]):\n",
    "    subject = dataset.get_subject(subject_sds_id)\n",
    "    subject.set_value(element='age', value=ages[idx])\n",
    "    subject.set_values({\n",
    "        \"subject id\": '',\n",
    "        'sex': sex[idx],\n",
    "        'species': species[idx],\n",
    "        'strain': strain[idx],\n",
    "        'RRID for strain': RRID_for_strain[idx],\n",
    "        'age category': age_category[idx],\n",
    "        'also in dataset': also_in_dataset[idx],\n",
    "        'member of': member_of[idx]})\n",
    "    \n",
    "    sample_anatomical_location = ['Breast'] * 2\n",
    "    also_in_dataset = ['Not Defined'] * 2\n",
    "    member_of = ['Not Defined'] * 2\n",
    "\n",
    "    for i, sample_sds_id in enumerate([\"sam-1\", \"sam-2\"]):\n",
    "        sample = subject.get_sample(sample_sds_id)\n",
    "        sample.set_values({\n",
    "            'was derived from': 'Not Defined',\n",
    "            'sample type': 'DCE-MRI Contrast Image {0}'.format(sample_sds_id),\n",
    "            'sample anatomical location': sample_anatomical_location[i],\n",
    "            'also in dataset': also_in_dataset[i],\n",
    "            'member of': member_of[i]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding or removing thumbnails\n",
    "\n",
    "Thumbnail images can be added to a data as follows. The manifest metadata file will be automatically updated when thumbnails are added.`thumbnail_0.jpg` will be set as the main thumbnail for the dataset on the data catalogue page of the DigitalTWINS platform's portal. Additional thumbnails can be sequentially numbered e.g. `thumbnail_1.jpg`. All thumbnails will be visible in the gallery view of a data catalogue in the portal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.add_thumbnail(\"../resources/example_raw_dataset/thumbnail_0.jpg\")\n",
    "dataset.add_thumbnail(\"../resources/example_raw_dataset/thumbnail_1.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thumbnail images can be removed by using the `remove_thumbnail` method e.g. `dataset.remove_thumbnail(\"../resources/example_raw_dataset/thumbnail_1.jpg\")`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking a dataset\n",
    "Dataset checking (validation) can be perform as follows. This will allow the fields of the dataset to be checked before it is submitted to the portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = sm.Validator()\n",
    "validator.validate_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, only basic validation has been implemented. More validation features will be added in future releases of `sparc-me`.\n",
    "\n",
    "## Feedback\n",
    "Once you have completed this tutorial, please complete [this survey](https://docs.google.com/forms/d/e/1FAIpQLSe-EsVz6ahz2FXFy906AZh68i50jRYnt3hQe-loc-1DaFWoFQ/viewform?usp=sf_link), which will allow us to improve this and future tutorials.\n",
    "\n",
    "## Next steps\n",
    "The [next tutorial](https://github.com/ABI-CTT-Group/digitaltwins-api/blob/main/tutorials/tutorial_5_uploading_datasets.ipynb) will show how to upload your dataset to your instance of the 12 LABOURS DigitalTWINS Platform using its Python API."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}