{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Exploring and downloading datasets\n",
    "\n",
    "## Introduction\n",
    "The 12 LABOURS DigitalTWINS Platform’s harmonised database is organised into Programs and Projects. For example, Exemplar Project 1 (EP1) is a project within the 12 LABOURS Program. Users can only access and download datasets from these projects once they have been granted access. See Tutorial 1 for information on how to request access and connect to the platform. This tutorial shows how to explore and download existing datasets from the DigitalTWINS Platform using its Python API.\n",
    "\n",
    "## Definitions\n",
    "API - Application Programming Interface used to access the features or data of an application or service.\n",
    "\n",
    "## Learning outcomes\n",
    "In this tutorial, you will learn how to:\n",
    "- access the platform using its Python API\n",
    "- find datasets stored in the platform\n",
    "- download datasets in SDS format.\n",
    "\n",
    "## Accessing the platform using its Python API\n",
    "First, we will use Python's built in `configparser` module to load a `config.ini` file that specifies the location and API access keys for your instance of the DigitalTWINS Platform.\n",
    "\n",
    "Please contact your DigitalTWINS Platform maintainer to access your `config.ini`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "import pathlib\n",
    "# Change the path below to point to the location of your config.ini file.\n",
    "config_path = pathlib.Path(r\"config.ini')\n",
    "                           \n",
    "config.read(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the DigitalTWINS Python API's `Querier` class to list or search for existing datasets in the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import digitaltwins as dts\n",
    "querier = dts.Querier(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing program and  projects in the platform\n",
    "\n",
    "A list of existing programs in the platform can be retrieved as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "programs = querier.get_all_programs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of existing projects within a program can be retrieved as follows. The optional `program` argument can be used to only list projects in a specific program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = querier.get_projects(program=programs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding datasets\n",
    "Each dataset stored in the platform has a unique identifier (ID). Datasets can be retrieved using the platform API's `Dataset` class. This provides multiple methods to help with accessing metadata files in a dataset without needing to download the entire dataset. For example, the `get_dataset_description` method will return a Python dictionary of metadata elements for the SDS dataset description metadata file. The Digital Twin Platform’s API documentation (TODO) lists all the methods available for accessing dataset metadata.\n",
    "\n",
    "The first step in accessing a specific dataset is to find the dataset's ID. There are multiple approaches to identify the ID for a dataset of interest. These are described below.\n",
    "\n",
    "### Using the data catalogue on the platform's portal\n",
    "Dataset IDs are included in each dataset listed on the data catalogue page of the 12 LABOURS DigitalTWINS platform's portal. \n",
    "\n",
    "TODO add screenshot.\n",
    "\n",
    "### Using the platform's API to list all datasets\n",
    "The `get_datasets` method of the `Querier` class allows a list of `Dataset` objects to be retrieved from the platform. The UID of a dataset can then be accessed using the `Dataset` classes `get_uid` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = querier.get_datasets(program=all, project=all)\n",
    "for dataset in datasets:\n",
    "    print(dataset.get_uid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the platform's API to search for datsets\n",
    "The `search_datasets` method of the `Querier` class allows for searching of datasets, and returns a python list of `Dataset` objects that match the search criteria . \n",
    "\n",
    "Currently, only searching text that matches exactly with the title of existing datasets in the platform is supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = 'dataset-1-version-1'\n",
    "datasets = querier.search_datasets(query=dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading datasets\n",
    "Datasets are stored in SDS format within the platforms harmonised database. We can use the DigitalTWINS Python API's `Downloader` class to select and download a dataset in SDS format. Once downloaded, the `sparc-me` Python module can be used explore the metadata in a dataset (see Tutorial 3).\n",
    "\n",
    "By default, datsets are downloaded to the current working directory, however, the `save_dir` optional argument can be specified to select a different download destination path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloader = dts.Downloader(config)\n",
    "downloader.download(dataset_id, save_dir='./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some datasets can be very large, so an option is provided to  only download the metadata files in a dataset, or the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloader.download(dataset_id, save_dir='./', metadata_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "The next tutorial will show how to load and explore SDS datasets using the sparc-me Python tool."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
